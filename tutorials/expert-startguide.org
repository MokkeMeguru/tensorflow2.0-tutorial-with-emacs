# -*- org-export-babel-evaluate: nil -*-
#+options: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline author:t
#+options: broken-links:nil c:nil creator:nil d:(not "LOGBOOK") date:t e:t
#+options: email:nil f:t inline:t num:t p:nil pri:nil prop:nil stat:t tags:t
#+options: tasks:t tex:t timestamp:t title:t toc:t todo:t |:t
#+title: エキスパートのための Tensorflow 2.0 入門
#+date: <2019-08-24 土>
#+author: MokkeMeguru
#+email: meguru.mokke@gmail.com
#+language: en
#+select_tags: export
#+exclude_tags: noexport
#+creator: Emacs 26.2 (Org mode 9.1.9)
#+LATEX_CLASS: extarticle
# #+LATEX_CLASS_OPTIONS: [a4paper, dvipdfmx, twocolumn, 8pt]
#+LATEX_CLASS_OPTIONS: [a4paper, dvipdfmx]
#+LATEX_HEADER: \usepackage{amsmath, amssymb, bm}
#+LATEX_HEADER: \usepackage{graphics}
#+LATEX_HEADER: \usepackage{color}
#+LATEX_HEADER: \usepackage{times}
#+LATEX_HEADER: \usepackage{longtable}
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage{fancyvrb}
#+LATEX_HEADER: \usepackage{indentfirst}
#+LATEX_HEADER: \usepackage{pxjahyper}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage[backend=biber, bibencoding=utf8, style=authoryear]{biblatex}
#+LATEX_HEADER: \usepackage[left=25truemm, right=25truemm]{geometry}
#+LATEX_HEADER: \usepackage{ascmac}
#+LATEX_HEADER: \usepackage{algorithm}
#+LATEX_HEADER: \usepackage{algorithmic}
#+LATEX_HEADER: \hypersetup{ colorlinks=true, citecolor=blue, linkcolor=red, urlcolor=orange}
#+LATEX_HEADER: \addbibresource{reference.bib}
#+DESCRIPTION:
#+KEYWORDS:
#+STARTUP: indent overview inlineimages
#+PROPERTY: header-args :eval never-export

* TensorFlow ライブラリのインポート
    #+NAME: d2d1180c-234c-4cff-983c-4396cf56f9da
    #+BEGIN_SRC ein-python :session localhost :results raw drawer :exports code :cache yes
    from __future__ import division, absolute_import
    from __future__ import print_function, unicode_literals
    from functools import reduce
    from tqdm import tqdm

    import tensorflow as tf
    from tensorflow.keras.layers import Dense, Flatten, Conv2D
    from tensorflow.keras import Model
  #+END_SRC

  #+RESULTS: d2d1180c-234c-4cff-983c-4396cf56f9da
  :results:
  :end:

* MNIST データセットの前処理
** データセットの読み込み

  #+NAME: 0d9589d8-002e-4af2-a164-3277d452ee56
  #+BEGIN_SRC ein-python :session localhost :results org drawer :exports code :cache yes
    mnist = tf.keras.datasets.mnist
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
    x_train, x_test = x_train / 255.0, x_test / 255.0

    x_train = x_train[..., tf.newaxis]
    x_test = x_test[..., tf.newaxis]
  #+END_SRC

  #+RESULTS: 0d9589d8-002e-4af2-a164-3277d452ee56
  :results:
  :end:

** データセットのシャッフル・バッチ化
   #+NAME: 877929db-dde2-412d-bdf9-5e5302366996
   #+BEGIN_SRC ein-python :session localhost :results drawer :exports both :cache yes
     train_ds = tf.data.Dataset.from_tensor_slices(
         (x_train, y_train)).shuffle(10000).batch(32)
     test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)
     print("dataset", train_ds)
   #+END_SRC

   #+RESULTS: 877929db-dde2-412d-bdf9-5e5302366996
   :results:
   dataset <BatchDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float64, tf.uint8)>
   :end:
   

* Keras モデルの作成
  #+NAME: af629887-cf24-45f3-a329-bc7c256d30f0
  #+BEGIN_SRC ein-python :session localhost :results raw drawer :exports code :cache yes
    class MyModel(Model):
        def __init__(self):
            super(MyModel, self).__init__()
            self.conv1 = Conv2D(32, 3, activation='relu')
            self.flatten = Flatten()
            self.d1 = Dense(128, activation='relu')
            self.d2 = Dense(10, activation='softmax')

        def call(self, x):
            return reduce(lambda x, f: f(x),
                          [x, self.conv1, self.flatten, self.d1, self.d2])


    model = MyModel()
  #+END_SRC

  #+RESULTS: af629887-cf24-45f3-a329-bc7c256d30f0
  :results:
  :end:

* 最適関数と損失関数の作成
  #+NAME: 7d1e2f1d-604b-4096-91be-1403519245e5
  #+BEGIN_SRC ein-python :session localhost :results raw drawer :exports code :cache yes
    loss_object = tf.keras.losses.SparseCategoricalCrossentropy()
    optimizer = tf.keras.optimizers.Adam()
  #+END_SRC

  #+RESULTS: 7d1e2f1d-604b-4096-91be-1403519245e5
  :results:
  :end:

* 訓練時のログの作成
  #+NAME: 3459187f-93e7-4819-927a-b2b911890cbe
  #+BEGIN_SRC ein-python :session localhost :results raw drawer :exports code :cache yes
    train_loss = tf.keras.metrics.Mean(name='train_loss')
    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(
        name='train_accuracy')

    test_loss = tf.keras.metrics.Mean(name='test_loss')
    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(
        name='test_accuracy')
  #+END_SRC

  #+RESULTS: 3459187f-93e7-4819-927a-b2b911890cbe
  :results:
  :end:

* モデルの訓練
** 訓練時の1ステップを定義
     #+NAME: 0c248821-cce0-4ad0-8d87-3549fe6057ba
     #+BEGIN_SRC ein-python :session localhost :results raw drawer :exports code :cache yes
       @tf.function
       def train_step(image, label):
         with tf.GradientTape() as tape:
           predictions = model(image)
           loss = loss_object(label, predictions)
           gradients = tape.gradient(loss, model.trainable_variables)
           optimizer.apply_gradients(zip(gradients, model.trainable_variables))

         train_loss(loss)
         train_accuracy(label, predictions)
     #+END_SRC

     #+RESULTS: 0c248821-cce0-4ad0-8d87-3549fe6057ba
     :results:
     :end:

** テスト時の1ステップを定義
      #+NAME: ee15d55b-b35d-474e-98b7-0a29681c97e1
      #+BEGIN_SRC ein-python :session localhost :results raw drawer :exports code :cache yes
        @tf.function
        def test_step(image, label):
            predictions = model(image)
            t_loss = loss_object(label, predictions)

            test_loss(t_loss)
            test_accuracy(label, predictions)
      #+END_SRC

      #+RESULTS: ee15d55b-b35d-474e-98b7-0a29681c97e1
      :results:
      :end:

** モデルを訓練する
#+NAME: f84f45e3-4017-49e1-92ba-1b77a14d1090
#+BEGIN_SRC ein-python :session localhost :results raw drawer :exports both :cache yes
  EPOCHS = 5

  for epoch in range(EPOCHS):
      for image, label in train_ds:
          train_step(image, label)

      for test_image, test_label in test_ds:
          test_step(test_image, test_label)

      template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'
      print(
          template.format(epoch + 1, train_loss.result(),
                          train_accuracy.result() * 100, test_loss.result(),
                          test_accuracy.result() * 100))
#+END_SRC

#+RESULTS: f84f45e3-4017-49e1-92ba-1b77a14d1090
:results:
Epoch 1, Loss: 0.1349046528339386, Accuracy: 95.96833801269531, Test Loss: 0.07161739468574524, Test Accuracy: 97.69999694824219

Epoch 2, Loss: 0.08821088820695877, Accuracy: 97.36000061035156, Test Loss: 0.06225990131497383, Test Accuracy: 98.0

Epoch 3, Loss: 0.06569895893335342, Accuracy: 98.02166748046875, Test Loss: 0.05950223654508591, Test Accuracy: 98.15666961669922

Epoch 4, Loss: 0.05297775939106941, Accuracy: 98.38541412353516, Test Loss: 0.061324529349803925, Test Accuracy: 98.16999816894531

Epoch 5, Loss: 0.04419006407260895, Accuracy: 98.64633178710938, Test Loss: 0.06336682289838791, Test Accuracy: 98.18800354003906
:end:
