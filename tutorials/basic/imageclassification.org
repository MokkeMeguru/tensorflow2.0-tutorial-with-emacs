# -*- org-export-babel-evaluate: nil -*-
#+options: ':nil *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline author:t
#+options: broken-links:nil c:nil creator:nil d:(not "LOGBOOK") date:t e:t
#+options: email:nil f:t inline:t num:t p:nil pri:nil prop:nil stat:t tags:t
#+options: tasks:t tex:t timestamp:t title:t toc:t todo:t |:t
#+title: エキスパートのための Tensorflow 2.0 入門
#+date: <2019-08-24 土>
#+author: MokkeMeguru
#+email: meguru.mokke@gmail.com
#+language: en
#+select_tags: export
#+exclude_tags: noexport
#+creator: Emacs 26.2 (Org mode 9.1.9)
#+LATEX_CLASS: extarticle
# #+LATEX_CLASS_OPTIONS: [a4paper, dvipdfmx, twocolumn, 8pt]
#+LATEX_CLASS_OPTIONS: [a4paper, dvipdfmx]
#+LATEX_HEADER: \usepackage{amsmath, amssymb, bm}
#+LATEX_HEADER: \usepackage{graphics}
#+LATEX_HEADER: \usepackage{color}
#+LATEX_HEADER: \usepackage{times}
#+LATEX_HEADER: \usepackage{longtable}
#+LATEX_HEADER: \usepackage{minted}
#+LATEX_HEADER: \usepackage{fancyvrb}
#+LATEX_HEADER: \usepackage{indentfirst}
#+LATEX_HEADER: \usepackage{pxjahyper}
#+LATEX_HEADER: \usepackage[utf8]{inputenc}
#+LATEX_HEADER: \usepackage[backend=biber, bibencoding=utf8, style=authoryear]{biblatex}
#+LATEX_HEADER: \usepackage[left=25truemm, right=25truemm]{geometry}
#+LATEX_HEADER: \usepackage{ascmac}
#+LATEX_HEADER: \usepackage{algorithm}
#+LATEX_HEADER: \usepackage{algorithmic}
#+LATEX_HEADER: \hypersetup{ colorlinks=true, citecolor=blue, linkcolor=red, urlcolor=orange}
#+LATEX_HEADER: \addbibresource{reference.bib}
#+DESCRIPTION:
#+KEYWORDS:
#+STARTUP: indent overview inlineimages
#+PROPERTY: header-args :eval never-export
* TensorFlow ライブラリのインポート
  #+NAME: 08bb0ced-8cbe-4e1f-8d8f-0a03de9e4b5c
  #+BEGIN_SRC ein-python :session localhost :results raw drawer :exports both
    from __future__ import division, absolute_import
    from __future__ import print_function, unicode_literals
    from functools import reduce

    import tensorflow as tf
    from tensorflow import keras

    import numpy as np
    import matplotlib.pyplot as plt

    print('tensorflow\'s version: {}'.format(tf.__version__))
  #+END_SRC

  #+RESULTS: 08bb0ced-8cbe-4e1f-8d8f-0a03de9e4b5c
  :results:
  tensorflow's version: 2.0.0-beta1
  :end:

* fashion MNIST のデータ読み込み
  fashion MNIST は服の画像とその服の種類のデータセット。服の種類についてクラス分類するのが一般的な用いられ方。

  #+CAPTION: fashion labels
  #+ATTR_LATEX: :environment tabular :align |c|c|
  |-------+-------------|
  | label | class       |
  |-------+-------------|
  |     0 | T-shirt/top |
  |     1 | Trouser     |
  |     2 | Pullover    |
  |     3 | Dress       |
  |     4 | Coat        |
  |     5 | Sandal      |
  |     6 | Shirt       |
  |     7 | Sneaker     |
  |     8 | Bag         |
  |     9 | Ankle boot  |
  |-------+-------------|
    

  #+NAME: 982feec1-aa1c-406e-89a6-a06611e3c07d
  #+BEGIN_SRC ein-python :session localhost :results raw drawer :exports both
    fashion_mnist = keras.datasets.fashion_mnist
    (train_images, train_labels), (test_images,
                                   test_labels) = fashion_mnist.load_data()

    class_names = [
        'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt',
        'Sneaker', 'Bag', 'Ankle boot'
    ]


    def print_infos(infolist: list):
        for info in infolist:
            print(info)


    print_infos([
        "image size", "-----------", "{}".format(train_images[0].shape), "\n",
        "sample size", "-----------", "train: {}".format(len(train_images)),
        "test  : {}".format(len(test_images)), "-----------"
    ])
  #+END_SRC

  #+RESULTS: 982feec1-aa1c-406e-89a6-a06611e3c07d
  :results:
  image size
  -----------
  (28, 28)


  sample size
  -----------
  train: 60000
  test  : 10000
  -----------
  :end:

** fashion MNIST の画像サンプル
  #+NAME: 4ff25e2f-f916-4b5a-a57e-47c16b46e28a
  #+BEGIN_SRC ein-python :session localhost :results raw drawer :exports both
    plt.figure()
    plt.imshow(train_images[0])
    plt.colorbar()
    plt.grid(False)
    plt.show()
  #+END_SRC

  #+RESULTS: 4ff25e2f-f916-4b5a-a57e-47c16b46e28a
  :results:
  [[file:ein-images/ob-ein-d4c771ea1dd071edb634be0488919792.png]]
  :end:
  
** 画像の正規化
画像サイズを [0, 255] から [0, 1] へ正規化する。
#+NAME: 729412ac-0be6-411c-a32a-98f4958a0ffe
  #+BEGIN_SRC ein-python :session localhost :results raw drawer :exports code
    train_images = train_images / 255.0
    test_images = test_images / 255.0

    plt.figure(figsize=(10, 10))
    for i in range(25):
        plt.subplot(5, 5, i + 1)
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
        plt.imshow(train_images[i], cmap='binary_r')
        plt.xlabel(class_names[train_labels[i]])
  #+END_SRC

  #+RESULTS: 729412ac-0be6-411c-a32a-98f4958a0ffe
  :results:
  [[file:ein-images/ob-ein-c7a00885052b5b4bbef9f911fc6d61b0.png]]
  :end:

* モデルの作成
  #+NAME: c3073c43-2ace-46dc-a1a0-ce899d545519
  #+BEGIN_SRC ein-python :session localhost :results raw drawer
    class MyModel(keras.Model):
        def __init__(self):
            super(MyModel, self).__init__()
            self.flatten = keras.layers.Flatten(input_shape=(28, 28))
            self.d1 = keras.layers.Dense(128, activation='relu')
            self.d2 = keras.layers.Dense(128, activation='softmax')

        def call(self, x):
            return reduce(lambda x, f: f(x), [x, self.flatten, self.d1, self.d2])


    model = MyModel()
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
  #+END_SRC

  #+RESULTS: c3073c43-2ace-46dc-a1a0-ce899d545519
  :results:
  :end:

* モデルの訓練
  #+NAME: d3ee3d4e-8536-43fa-96d6-34495abb5577
  #+BEGIN_SRC ein-python :session localhost :results raw drawer :exports both
  model.fit(train_images, train_labels, epochs=10)
  #+END_SRC

  #+RESULTS: d3ee3d4e-8536-43fa-96d6-34495abb5577
  :results:  
  WARNING: Logging before flag parsing goes to stderr.
  W0824 17:06:10.599414 140015014143616 deprecation.py:323] From /home/meguru/Github/tensorflow-2.0tutorial-with-emacs/venv/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
  Instructions for updating:
  Use tf.where in 2.0, which has the same broadcast rule as np.where

  Train on 60000 samples
  Epoch 1/10
  60000/60000 [==============================] - 2s 39us/sample - loss: 2.4317 - accuracy: 0.1011
  Epoch 2/10
  60000/60000 [==============================] - 2s 37us/sample - loss: 2.3056 - accuracy: 0.0992
  Epoch 3/10
  60000/60000 [==============================] - 2s 38us/sample - loss: 2.3055 - accuracy: 0.1002
  Epoch 4/10
  60000/60000 [==============================] - 2s 37us/sample - loss: 2.3050 - accuracy: 0.0997
  Epoch 5/10
  60000/60000 [==============================] - 2s 37us/sample - loss: 2.3047 - accuracy: 0.1015
  Epoch 6/10
  60000/60000 [==============================] - 2s 37us/sample - loss: 2.3045 - accuracy: 0.1010
  Epoch 7/10
  60000/60000 [==============================] - 2s 37us/sample - loss: 2.3044 - accuracy: 0.1000
  Epoch 8/10
  60000/60000 [==============================] - 2s 37us/sample - loss: 2.3041 - accuracy: 0.1011
  Epoch 9/10
  60000/60000 [==============================] - 2s 37us/sample - loss: 2.3040 - accuracy: 0.0983
  Epoch 10/10
  60000/60000 [==============================] - 2s 37us/sample - loss: 2.3037 - accuracy: 0.0977

  <tensorflow.python.keras.callbacks.History at 0x7f574e468b50>
  :end:


